{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueyuQzJ8AZAr"
   },
   "source": [
    "# Section 1 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiRYuhybIMyw"
   },
   "outputs": [],
   "source": [
    "with open('s.txt', encoding=\"utf8\") as file:\n",
    "     s = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt5QGrMcIT1s"
   },
   "outputs": [],
   "source": [
    "def remove_newlines_tabs(text):    \n",
    "    # Replacing all the occurrences of \\n,\\\\n,\\t,\\\\ with a space.\n",
    "    Formatted_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ')\n",
    "    return Formatted_text\n",
    "s = remove_newlines_tabs(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rep7r8CDsK0"
   },
   "outputs": [],
   "source": [
    "List = s.split(\"',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayL1_O_jEPvy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(List, columns = ['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSUG2S_6HdPh"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher \n",
    "\n",
    "from spacy import displacy \n",
    "import visualise_spacy_tree\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# load english language model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bjgCy4JIhj-"
   },
   "outputs": [],
   "source": [
    "# function for rule 1: noun(subject), verb, noun(object)\n",
    "def rule1(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        # if the token is a verb\n",
    "        if (token.pos_=='VERB'):\n",
    "            \n",
    "            phrase =''\n",
    "            \n",
    "            # only extract noun or pronoun subjects\n",
    "            for sub_tok in token.lefts:\n",
    "                \n",
    "                if (sub_tok.dep_ in ['nsubj','nsubjpass']) and (sub_tok.pos_ in ['NOUN','PROPN','PRON']):\n",
    "                    \n",
    "                    # add subject to the phrase\n",
    "                    phrase += sub_tok.text\n",
    "\n",
    "                    # save the root of the verb in phrase\n",
    "                    phrase += ' '+token.lemma_ \n",
    "\n",
    "                    # check for noun or pronoun direct objects\n",
    "                    for sub_tok in token.rights:\n",
    "                        \n",
    "                        # save the object in the phrase\n",
    "                        if (sub_tok.dep_ in ['dobj']) and (sub_tok.pos_ in ['NOUN','PROPN']):\n",
    "                                    \n",
    "                            phrase += ' '+sub_tok.text\n",
    "                            sent.append(phrase)\n",
    "            \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFF3a1sNIhnC"
   },
   "outputs": [],
   "source": [
    "output_1 = rule1(plan_risk_management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUOBlqD0Ihp8",
    "outputId": "4f5467b8-ff8a-467f-e0c9-b51c4cf91f0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Management include processes',\n",
       " 'risks affect project',\n",
       " 'causes include requirement',\n",
       " 'conditions include aspects',\n",
       " 'risks assign reserve',\n",
       " 'risk represent effect',\n",
       " 'it include sources',\n",
       " 'risk represent exposure',\n",
       " 'organization accept risk',\n",
       " 'organization tolerate risk',\n",
       " 'attitude include appetite',\n",
       " 'organization select response',\n",
       " 'responses reflect organization',\n",
       " 'planning enhance probability',\n",
       " 'plan provide areas',\n",
       " 'charter provide inputs',\n",
       " 'register provide overview',\n",
       " 'team allocate resources',\n",
       " 'team allocate resources Judgment',\n",
       " 'teams hold meetings',\n",
       " 'Attendees include manager',\n",
       " 'plan include following',\n",
       " 'Roles define lead',\n",
       " 'Roles define lead Defines',\n",
       " 'categories provide means',\n",
       " 'approaches use structure',\n",
       " 'organization use framework',\n",
       " 'formats describe content',\n",
       " 'formats describe content reports',\n",
       " 'formats describe content reports documents']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS0E75bBAKW7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aH-UwyrANyU"
   },
   "source": [
    "# Transformer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RXEHKxRAsE7"
   },
   "outputs": [],
   "source": [
    "with open('text1.txt', encoding=\"utf8\") as file:\n",
    "     plan_risk_management = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZ346yayBHpV"
   },
   "outputs": [],
   "source": [
    "def remove_newlines_tabs(text):    \n",
    "    # Replacing all the occurrences of \\n,\\\\n,\\t,\\\\ with a space.\n",
    "    Formatted_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ')\n",
    "    return Formatted_text\n",
    "plan_risk_management = remove_newlines_tabs(plan_risk_management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7kjxgNvBX1C"
   },
   "outputs": [],
   "source": [
    "text = plan_risk_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8u5_aV4FaHz",
    "outputId": "9d9b3d72-b401-4e0d-d607-4d98f772c0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GieeUrhMFe9b",
    "outputId": "d338d637-1975-40b6-f9bf-1f341dd11286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Q-1dhNnFinF",
    "outputId": "f0900817-ce0f-40b2-9294-2c7870069fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpkkVf9LBO17",
    "outputId": "d660662d-2e8c-487e-e777-99b358a23b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning sentences...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 4\n",
    "MAX_WORDS = 200\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Lemmatize, tokenize, crop and remove stop words.\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w for w in word_tokenize(sentence)]\n",
    "    token = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens    \n",
    "\n",
    "\n",
    "def clean_sentences(df):\n",
    "    \"\"\"\n",
    "    Remove irrelavant characters (in new column clean_sentence).\n",
    "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
    "    \"\"\"\n",
    "    print('Cleaning sentences...')\n",
    "    df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
    "    df['tok_lem_sentence'] = df['clean_sentence'].apply(\n",
    "        lambda x: tokenizer(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True))\n",
    "    return df\n",
    "    \n",
    "df = clean_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "Hggtr4xWFnf7",
    "outputId": "7fb3c464-510f-4a98-a64e-22df7dface7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>tok_lem_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['PROJECT RISK MANAGEMENT Project Risk Managem...</td>\n",
       "      <td>project risk management project risk managem...</td>\n",
       "      <td>[project, risk, management, project, risk, man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'The objectives of project risk management a...</td>\n",
       "      <td>the objectives of project risk management a...</td>\n",
       "      <td>[the, objective, of, project, risk, management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Plan Risk Management is the process of defi...</td>\n",
       "      <td>plan risk management is the process of defi...</td>\n",
       "      <td>[plan, risk, management, is, the, process, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Identify Risks is the process of determinin...</td>\n",
       "      <td>identify risks is the process of determinin...</td>\n",
       "      <td>[identify, risk, is, the, process, of, determi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Perform Qualitative Risk Analysis is the pr...</td>\n",
       "      <td>perform qualitative risk analysis is the pr...</td>\n",
       "      <td>[perform, qualitative, risk, analysis, is, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>'The specific combinations of probability an...</td>\n",
       "      <td>the specific combinations of probability an...</td>\n",
       "      <td>[the, specific, combination, of, probability, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>'Revised stakeholders’ tolerances Stakeholde...</td>\n",
       "      <td>revised stakeholders  tolerances stakeholde...</td>\n",
       "      <td>[revised, stakeholder, tolerance, stakeholder,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>'Reporting formats Reporting formats define ...</td>\n",
       "      <td>reporting formats reporting formats define ...</td>\n",
       "      <td>[reporting, format, reporting, format, define,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>'formats describes the content and format of...</td>\n",
       "      <td>formats describes the content and format of...</td>\n",
       "      <td>[format, describes, the, content, and, format,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>'Tracking Tracking documents how risk activi...</td>\n",
       "      <td>tracking tracking documents how risk activi...</td>\n",
       "      <td>[tracking, tracking, document, how, risk, acti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  ...                                   tok_lem_sentence\n",
       "0    ['PROJECT RISK MANAGEMENT Project Risk Managem...  ...  [project, risk, management, project, risk, man...\n",
       "1      'The objectives of project risk management a...  ...  [the, objective, of, project, risk, management...\n",
       "2      'Plan Risk Management is the process of defi...  ...  [plan, risk, management, is, the, process, of,...\n",
       "3      'Identify Risks is the process of determinin...  ...  [identify, risk, is, the, process, of, determi...\n",
       "4      'Perform Qualitative Risk Analysis is the pr...  ...  [perform, qualitative, risk, analysis, is, the...\n",
       "..                                                 ...  ...                                                ...\n",
       "98     'The specific combinations of probability an...  ...  [the, specific, combination, of, probability, ...\n",
       "99     'Revised stakeholders’ tolerances Stakeholde...  ...  [revised, stakeholder, tolerance, stakeholder,...\n",
       "100    'Reporting formats Reporting formats define ...  ...  [reporting, format, reporting, format, define,...\n",
       "101    'formats describes the content and format of...  ...  [format, describes, the, content, and, format,...\n",
       "102    'Tracking Tracking documents how risk activi...  ...  [tracking, tracking, document, how, risk, acti...\n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIkjFs5TF8Cd"
   },
   "outputs": [],
   "source": [
    "def extract_best_indices(m, topk, mask=None):\n",
    "    \"\"\"\n",
    "    Use sum of the cosine distance over all tokens.\n",
    "    m (np.array): cos matrix of shape (nb_in_tokens, nb_dict_tokens)\n",
    "    topk (int): number of indices to return (from high to lowest in order)\n",
    "    \"\"\"\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \n",
    "    if mask is not None:\n",
    "        assert mask.shape == m.shape\n",
    "        mask = mask[index]\n",
    "    else:\n",
    "        mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:topk]  \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJqKvLw5GBPi"
   },
   "outputs": [],
   "source": [
    "query_sentence = 'what is the project charter' \n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2KLi3Vn_GlL"
   },
   "outputs": [],
   "source": [
    "! pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgr9jiPo_Ch-"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2hlqVx9G1Y0"
   },
   "outputs": [],
   "source": [
    "corpus_embeddings = model.encode(df.sentence.values, convert_to_tensor=True)\n",
    "query_embedding = model.encode(query_sentence, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "vB7yrEVH_i9r",
    "outputId": "b2588ae2-51b6-4506-8ca5-02d14448595b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: what is the project charter\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"  '... Project Charter Described in Section ....\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"  'The project charter can provide various inputs such as high level risks, high level project descriptions, and high level requirements.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"  'The stakeholder register, which contains all details related to the project’s stakeholders, provides an overview of their roles.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# We use cosine-similarity and torch.topk to find the highest 3 scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=3)\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query_sentence)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    score = score.cpu().data.numpy() \n",
    "    idx = idx.cpu().data.numpy()\n",
    "    display(df['sentence'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFfOQ5FMIWzO"
   },
   "outputs": [],
   "source": [
    "query_sentence_2 = 'what are the Analytical Techniques ? ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdZSZphLIrbs"
   },
   "outputs": [],
   "source": [
    "corpus_embeddings = model.encode(df.sentence.values, convert_to_tensor=True)\n",
    "query_embedding = model.encode(query_sentence_2, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "tjnUhioOItaq",
    "outputId": "5061dc22-504a-4ddb-bfb5-da67c378fb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: what are the Analytical Techniques ? \n",
      "\n",
      "Top 5 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"  '.. Plan Risk Management: Tools and Techniques ... Analytical Techniques Analytical techniques are used to understand and define the overall risk management context of the project.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"  'Perform Quantitative Risk Analysis is the process of numerically analyzing the effect of identified risks on overall project objectives.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"  'Other techniques, such as the use of strategic risk scoring sheets, are used to provide a high level assessment of the risk exposure of the project based on the overall project context.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# We use cosine-similarity and torch.topk to find the highest 3 scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=3)\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query_sentence_2)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    score = score.cpu().data.numpy() \n",
    "    idx = idx.cpu().data.numpy()\n",
    "    display(df['sentence'].iloc[idx])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
